{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1077a249-3124-49d1-93bb-2e65b07aa288",
   "metadata": {},
   "source": [
    "## Presidential results (D%, R%, two-party %)\n",
    "\n",
    "Difficulty: Easy\n",
    "\n",
    "Sources: MIT Election Data & Science Lab (county & state returns), state SOS\n",
    "\n",
    "MIT Election Lab\n",
    "Quality issues: late-certified adjustments are rare but check state certification dates. Third-party vote handlingâ€”compute two-party share.\n",
    "Estimated time: hours to 1 day using MIT Election Lab CSVs.\n",
    "\n",
    "https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/42MVDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc3d215-1b5c-4cde-a12e-662ddc1f714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9c20d1-cc87-4fbf-a552-1b404cfd4dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0eeefc-d61e-470d-a83b-a9cdff662b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyjanitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd90927e-7ea9-4874-9e96-326c66fb33d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131592c4-71a4-4fe2-a7a4-275190430ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/POTUS/1976-2020-president.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14d3e2b-9ab4-4472-9655-8b4177cc874b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbe517a-5b2c-44fa-a031-c0cd606fd43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === 1. Load the data ===\n",
    "df = pd.read_csv(\"data/POTUS/1976-2020-president.csv\")\n",
    "\n",
    "df[\"state_fips\"] = df[\"state_fips\"].astype(str).str.zfill(2)\n",
    "\n",
    "# Normalize column names just in case (some datasets differ in case)\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "# === 2. Keep only relevant columns ===\n",
    "cols = [\"year\", \"state\", \"state_po\", \"state_fips\", \"party_detailed\", \"candidatevotes\", \"totalvotes\"]\n",
    "df = df[cols].rename(\n",
    "    columns = {\"candidatevotes\": \"candidate_votes\", \"totalvotes\": \"total_votes\"}\n",
    ")\n",
    "\n",
    "# === 3. Group parties into Dem, Rep, or Other ===\n",
    "df[\"party_grouped\"] = df[\"party_detailed\"].apply(\n",
    "    lambda x: (\n",
    "        \"dem\" if \"democrat\" in str(x).lower()\n",
    "        else \"rep\" if \"republican\" in str(x).lower()\n",
    "        else \"other\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# === 4. Aggregate votes by year, state, and party group ===\n",
    "pivot_df = (\n",
    "    df.groupby([\"year\", \"state\", \"state_po\", \"state_fips\", \"party_grouped\"])[\"candidate_votes\"]\n",
    "    .sum()\n",
    "    .unstack(fill_value=0)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# === 5. Merge in total votes (max should be same per state-year) ===\n",
    "total_votes = df.groupby([\"year\", \"state\", \"state_po\", \"state_fips\"])[\"total_votes\"].max().reset_index()\n",
    "\n",
    "merged = pivot_df.merge(total_votes, on=[\"year\", \"state\", \"state_po\", \"state_fips\"], how=\"left\")\n",
    "\n",
    "# === 6. Compute party vote percentages ===\n",
    "for party in [\"dem\", \"rep\", \"other\"]:\n",
    "    merged[f\"{party.lower()}_pct\"] = (merged[party]*100 / merged[\"total_votes\"]).round(2)\n",
    "\n",
    "# === 7. Compute Demâ€“Rep difference ===\n",
    "merged[\"d_r_diff\"] = (merged[\"dem_pct\"] - merged[\"rep_pct\"]).round(2)\n",
    "\n",
    "# === 8. Optional: sort and inspect ===\n",
    "merged = merged.sort_values([\"year\", \"state_po\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "#print(merged.head())\n",
    "display(merged)\n",
    "# === 9. Optional: save output ===\n",
    "merged.to_csv(\"data/potus_votes_bystate.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c187d56-0686-4aea-b456-badeefa22b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nation = (\n",
    "    merged.groupby(\"year\", as_index=False)\n",
    "      .agg({\n",
    "          \"dem\": \"sum\",\n",
    "          \"rep\": \"sum\",\n",
    "          \"other\": \"sum\",\n",
    "          \"totalvotes\": \"sum\"\n",
    "      })\n",
    "      .assign(\n",
    "          dem_pct=lambda d: (100 * d.dem / d.totalvotes).round(2),\n",
    "          rep_pct=lambda d: (100 * d.rep / d.totalvotes).round(2),\n",
    "          other_pct=lambda d: (100 * d.other / d.totalvotes).round(2),\n",
    "          d_r_diff=lambda d: (d.dem_pct - d.rep_pct).round(2)\n",
    "      )\n",
    ")\n",
    "\n",
    "print(nation.head())\n",
    "nation.to_csv(\"data/potus_votes_national.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cc8937-6e5d-4475-81b3-43600d3d85cb",
   "metadata": {},
   "source": [
    "# 2024 POTUS election data\n",
    "\n",
    "Source: FEC.gov [Excel file](https://view.officeapps.live.com/op/view.aspx?src=https%3A%2F%2Fwww.fec.gov%2Fresources%2Fcms-content%2Fdocuments%2F2024presgeresults.xlsx&wdOrigin=BROWSELINK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255e56be-0a0d-4709-b048-2f15a225100b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import janitor\n",
    "df24 = pd.read_excel(\"data/POTUS/2024presgeresults.xlsx\", header=0, nrows=51)\n",
    "df24 = df24.clean_names()\n",
    "\n",
    "df24 = df24[[\"state\", \"electoral_votes\", \"electoral_vote_trump_r_\", \"electoral_vote_harris_d_\", \"harris\", \"trump\", \"total_votes\"]].rename(\n",
    "    columns = {\"state\": \"state_po\", \"electoral_votes\": \"ev_total\", \"electoral_vote_trump_r_\": \"ev_rep\", \"electoral_vote_harris_d_\": \"ev_dem\"\n",
    "               , \"harris\": \"dem\", \"trump\":\"rep\"}\n",
    ")\n",
    "\n",
    "num_cols = [c for c in df24.columns if c != \"state_po\"]\n",
    "df24[num_cols] = df24[num_cols].apply(pd.to_numeric, errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "# calc xx_pct columns\n",
    "for party in [\"dem\", \"rep\"]:\n",
    "    df24[f\"{party.lower()}_pct\"] = (df24[party]*100 / df24[\"total_votes\"]).round(2)\n",
    "\n",
    "# calc diffs\n",
    "df24[\"d_r_diff\"] = (df24[\"dem_pct\"] - df24[\"rep_pct\"]).round(2)\n",
    "df24[\"r_d_diff\"] = (df24[\"rep_pct\"] - df24[\"dem_pct\"]).round(2)\n",
    "\n",
    "# add \"year\" and move to first column\n",
    "df24[\"year\"] = 2024\n",
    "col = \"year\"\n",
    "df24 = df24[[col] + [c for c in df24.columns if c != col]]\n",
    "\n",
    "df24\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3a43ff-4271-40ec-92f3-191dde38f898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc09ac7f-bf6d-4863-b638-42f2f9476b4b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Electoral College\n",
    "\n",
    "### 1976-2020 compiled\n",
    "https://huggingface.co/datasets/fdaudens/us-presidential-elections-with-electoral-college\n",
    "\n",
    "### 2024 data from archives.gov\n",
    "https://www.archives.gov/electoral-college/202"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d4fe3a-740b-44e8-bda9-4940c1fd42b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2024 Electoral College - web scrape\n",
    "from https://www.archives.gov/electoral-college/202\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38991c04-e9fc-41b4-b55a-440ec902e0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import unicodedata\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO\n",
    "\n",
    "# ===== Candidate â†’ Party map (1976â€“2024) =====\n",
    "# Use LAST NAMES (normalized) as keys; mapping happens on normalized header text.\n",
    "BASE_MAP_BY_YEAR = {\n",
    "    1976: {'carter':'DEM','ford':'REP','reagan':'REP'},  # WA faithless to Reagan (REP)\n",
    "    1980: {'carter':'DEM','reagan':'REP','anderson':'OTHER'},\n",
    "    1984: {'mondale':'DEM','reagan':'REP'},\n",
    "    1988: {'dukakis':'DEM','bush':'REP','bentsen':'DEM'},  # WV faithless to Bentsen (DEM)\n",
    "    1992: {'clinton':'DEM','bush':'REP','perot':'OTHER'},\n",
    "    1996: {'clinton':'DEM','dole':'REP','perot':'OTHER'},\n",
    "    2000: {'gore':'DEM','bush':'REP'},\n",
    "    2004: {'kerry':'DEM','bush':'REP','edwards':'DEM'},    # MN faithless to Edwards (DEM)\n",
    "    2008: {'obama':'DEM','mccain':'REP'},\n",
    "    2012: {'obama':'DEM','romney':'REP'},\n",
    "    2016: {\n",
    "        'clinton':'DEM','trump':'REP',\n",
    "        'powell':'REP','kasich':'REP','paul':'REP',\n",
    "        'sanders':'OTHER','faith spotted eagle':'OTHER','spotted eagle':'OTHER','eagle':'OTHER'\n",
    "    },\n",
    "    2020: {'biden':'DEM','trump':'REP'},\n",
    "    2024: {'harris':'DEM','trump':'REP'}\n",
    "}\n",
    "\n",
    "# ===== Helpers =====\n",
    "def flatten_cols(cols):\n",
    "    out = []\n",
    "    for c in cols:\n",
    "        if isinstance(c, tuple):\n",
    "            c = \" \".join([str(x) for x in c if x is not None])\n",
    "        out.append(str(c))\n",
    "    return out\n",
    "\n",
    "def normalize_header(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize NARA header strings so candidate names are detectable:\n",
    "    - ascii fold (remove accents)\n",
    "    - lower-case\n",
    "    - collapse whitespace\n",
    "    - remove punctuation\n",
    "    - drop phrases like 'for president', 'president', 'vice president'\n",
    "    - drop trailing ', of <state>...' fragments\n",
    "    \"\"\"\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "\n",
    "    # ASCII fold and lowercase\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    s = \"\".join(ch for ch in s if not unicodedata.combining(ch)).lower()\n",
    "\n",
    "    # Replace NBSP etc. with spaces, collapse whitespace\n",
    "    s = re.sub(r\"\\s+\", \" \", s.replace(\"\\xa0\", \" \")).strip()\n",
    "\n",
    "    # Remove obvious prefixes\n",
    "    s = re.sub(r\"^(for\\s+)?(vice\\s+)?president\\s+\", \"\", s)\n",
    "\n",
    "    # Remove \", of <place>...\" tail\n",
    "    s = re.sub(r\",?\\s+of\\s+.+$\", \"\", s)\n",
    "\n",
    "    # Remove non-letters except spaces (keep hyphens for names like 'spotted eagle')\n",
    "    s = re.sub(r\"[^a-z\\s-]\", \"\", s).strip()\n",
    "\n",
    "    return s\n",
    "\n",
    "def find_target_table(dfs):\n",
    "    for df in dfs:\n",
    "        cols = flatten_cols(df.columns)\n",
    "        if any(re.search(r\"\\bstate\\b\", c, re.I) for c in cols) and \\\n",
    "           any(re.search(r\"\\belectoral|votes?\\b\", c, re.I) for c in cols):\n",
    "            df2 = df.copy()\n",
    "            df2.columns = cols\n",
    "            return df2\n",
    "    return None\n",
    "\n",
    "def classify_candidate(col_name_raw: str, year: int) -> str:\n",
    "    \"\"\"\n",
    "    Classify a candidate column into DEM/REP/OTHER using normalized header text.\n",
    "    Works even when headers look like 'For President Jimmy Carter, of Georgia'.\n",
    "    \"\"\"\n",
    "    name = normalize_header(col_name_raw)\n",
    "    mapping = BASE_MAP_BY_YEAR.get(year, {})\n",
    "\n",
    "    # Try multi-word keys first (e.g., 'faith spotted eagle'), then single last names\n",
    "    # Sort keys by length desc so longer phrases match first\n",
    "    for key in sorted(mapping.keys(), key=len, reverse=True):\n",
    "        if key in name:\n",
    "            return mapping[key]\n",
    "\n",
    "    # Also try just the last token (often the last name)\n",
    "    tokens = name.split()\n",
    "    if tokens:\n",
    "        last = tokens[-1]\n",
    "        for key in mapping.keys():\n",
    "            if key == last:\n",
    "                return mapping[key]\n",
    "\n",
    "    return \"OTHER\"\n",
    "\n",
    "# ===== Scraper =====\n",
    "def scrape_year(year: int) -> pd.DataFrame:\n",
    "    url = f\"https://www.archives.gov/electoral-college/{year}\"\n",
    "    print(f\"\\nScraping {year} â€” {url}\")\n",
    "    resp = requests.get(url, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "    dfs = pd.read_html(StringIO(str(soup)), flavor=\"lxml\")\n",
    "    tbl = find_target_table(dfs)\n",
    "    if tbl is None:\n",
    "        raise RuntimeError(\"Could not locate Electoral College Votes by State table.\")\n",
    "\n",
    "    # Clean table & headers\n",
    "    tbl.columns = flatten_cols(tbl.columns)\n",
    "    first_col = tbl.columns[0]\n",
    "    tbl = tbl.rename(columns={first_col: \"state_raw\"})\n",
    "    # Drop totals rows early (by text)\n",
    "    tbl = tbl[~tbl[\"state_raw\"].astype(str).str.contains(r\"\\btotal\\b\", case=False, na=False)]\n",
    "    tbl[\"state\"] = tbl[\"state_raw\"].astype(str).str.replace(r\"\\s*\\*+$\", \"\", regex=True).str.strip()\n",
    "\n",
    "    # Identify EV total column (varies by year)\n",
    "    ev_total_col = None\n",
    "    for c in tbl.columns[1:]:\n",
    "        if re.search(r\"\\belectoral\\b\", c, re.I) and re.search(r\"\\bvote|votes\\b\", c, re.I):\n",
    "            ev_total_col = c\n",
    "            break\n",
    "    if ev_total_col is None:\n",
    "        # fallback: pick first column that's >90% numeric\n",
    "        for c in tbl.columns[1:]:\n",
    "            ser = pd.to_numeric(tbl[c], errors=\"coerce\")\n",
    "            if ser.notna().mean() > 0.9:\n",
    "                ev_total_col = c\n",
    "                break\n",
    "    if ev_total_col is None:\n",
    "        raise RuntimeError(\"Could not identify EV total column.\")\n",
    "\n",
    "    # Coerce numerics\n",
    "    for c in tbl.columns:\n",
    "        if c not in (\"state_raw\", \"state\"):\n",
    "            tbl[c] = pd.to_numeric(tbl[c], errors=\"coerce\")\n",
    "\n",
    "    numeric_cols = [c for c in tbl.columns if c not in (\"state_raw\",\"state\") and pd.api.types.is_numeric_dtype(tbl[c])]\n",
    "    cand_cols = [c for c in numeric_cols if c != ev_total_col]\n",
    "\n",
    "    # Classify columns by party with normalized headers\n",
    "    dem_cols, rep_cols, oth_cols = [], [], []\n",
    "    for c in cand_cols:\n",
    "        party = classify_candidate(c, year)\n",
    "        if party == \"DEM\":\n",
    "            dem_cols.append(c)\n",
    "        elif party == \"REP\":\n",
    "            rep_cols.append(c)\n",
    "        else:\n",
    "            oth_cols.append(c)\n",
    "\n",
    "    # Debug visibility: show how columns were classified this year\n",
    "    print(f\"  EV total col: {ev_total_col}\")\n",
    "    print(f\"  DEM cols: {dem_cols}\")\n",
    "    print(f\"  REP cols: {rep_cols}\")\n",
    "    print(f\"  OTHER cols: {oth_cols}\")\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"year\": year,\n",
    "        \"state\": tbl[\"state\"],\n",
    "        \"ev_total\": tbl[ev_total_col]\n",
    "    })\n",
    "\n",
    "    out[\"ev_dem\"]   = tbl[dem_cols].sum(axis=1, numeric_only=True) if dem_cols else 0\n",
    "    out[\"ev_rep\"]   = tbl[rep_cols].sum(axis=1, numeric_only=True) if rep_cols else 0\n",
    "    out[\"ev_other\"] = tbl[oth_cols].sum(axis=1, numeric_only=True) if oth_cols else 0\n",
    "\n",
    "    # Keep only real rows (some junk header rows have NaN/0 totals)\n",
    "    out = out.dropna(subset=[\"ev_total\"])\n",
    "    out = out[out[\"ev_total\"] > 0]\n",
    "\n",
    "    # Balance check & correction (protect against unclassified columns)\n",
    "    diff = out[\"ev_total\"] - (out[\"ev_dem\"] + out[\"ev_rep\"] + out[\"ev_other\"])\n",
    "    if (diff != 0).any():\n",
    "        # Add any leftover to OTHER (rare; indicates an unmapped column)\n",
    "        out[\"ev_other\"] = (out[\"ev_other\"] + diff).clip(lower=0)\n",
    "\n",
    "    # Integers\n",
    "    out[[\"ev_total\",\"ev_dem\",\"ev_rep\",\"ev_other\"]] = out[[\"ev_total\",\"ev_dem\",\"ev_rep\",\"ev_other\"]].round(0).astype(\"Int64\")\n",
    "\n",
    "    # Sort & return\n",
    "    out = out.sort_values([\"year\",\"state\"]).reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "def main():\n",
    "    years = list(range(1976, 2025, 4))\n",
    "    frames = []\n",
    "    for y in years:\n",
    "        try:\n",
    "            frames.append(scrape_year(y))\n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR {y}: {e}\")\n",
    "        time.sleep(0.8)\n",
    "\n",
    "    if not frames:\n",
    "        print(\"No data scraped.\")\n",
    "        return\n",
    "\n",
    "    df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "    # Normalize D.C. naming (rare variants)\n",
    "    dc_map = {\n",
    "        'district of columbia':'District of Columbia',\n",
    "        'washington, dc':'District of Columbia',\n",
    "        'washington, d.c.':'District of Columbia',\n",
    "        'd.c.':'District of Columbia',\n",
    "        'dc':'District of Columbia'\n",
    "    }\n",
    "    df[\"state\"] = df[\"state\"].str.strip()\n",
    "    df[\"state\"] = df[\"state\"].replace(dc_map)\n",
    "\n",
    "    # Sanity check\n",
    "    bad = df.eval(\"ev_dem + ev_rep + ev_other != ev_total\")\n",
    "    if bad.any():\n",
    "        print(\"âš ï¸ rows not summing to ev_total (inspect):\")\n",
    "        print(df.loc[bad, [\"year\",\"state\",\"ev_dem\",\"ev_rep\",\"ev_other\",\"ev_total\"]])\n",
    "\n",
    "    df.to_csv(\"nara_electoral_votes_by_party_1976_2024.csv\", index=False)\n",
    "    print(\"\\nâœ… Saved: nara_electoral_votes_by_party_1976_2024.csv\")\n",
    "    print(f\"Rows: {len(df)} | Years: {sorted(df['year'].unique().tolist())}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d3b6fa-1d24-49de-b2d2-139e44bb6969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_year(year: int) -> pd.DataFrame:\n",
    "    import textwrap\n",
    "    url = f\"https://www.archives.gov/electoral-college/{year}\"\n",
    "    print(f\"\\nScraping {year} â€” {url}\")\n",
    "    resp = requests.get(url, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "    dfs = pd.read_html(StringIO(str(soup)), flavor=\"lxml\")\n",
    "    tbl = find_target_table(dfs)\n",
    "    if tbl is None:\n",
    "        raise RuntimeError(\"Could not locate Electoral College Votes by State table.\")\n",
    "\n",
    "    # Flatten header\n",
    "    tbl.columns = flatten_cols(tbl.columns)\n",
    "    first_col = tbl.columns[0]\n",
    "    tbl = tbl.rename(columns={first_col: \"state_raw\"})\n",
    "    tbl = tbl[~tbl[\"state_raw\"].astype(str).str.contains(r\"\\btotal\\b\", case=False, na=False)]\n",
    "    tbl[\"state\"] = tbl[\"state_raw\"].astype(str).str.replace(r\"\\s*\\*+$\", \"\", regex=True).str.strip()\n",
    "\n",
    "    # Identify EV total column\n",
    "    ev_total_col = None\n",
    "    for c in tbl.columns[1:]:\n",
    "        if re.search(r\"\\belectoral\\b\", c, re.I) and re.search(r\"\\bvote|votes\\b\", c, re.I):\n",
    "            ev_total_col = c\n",
    "            break\n",
    "    if ev_total_col is None:\n",
    "        for c in tbl.columns[1:]:\n",
    "            ser = pd.to_numeric(tbl[c], errors=\"coerce\")\n",
    "            if ser.notna().mean() > 0.9:\n",
    "                ev_total_col = c\n",
    "                break\n",
    "\n",
    "    for c in tbl.columns:\n",
    "        if c not in (\"state_raw\",\"state\"):\n",
    "            tbl[c] = pd.to_numeric(tbl[c], errors=\"coerce\")\n",
    "\n",
    "    numeric_cols = [c for c in tbl.columns if c not in (\"state_raw\",\"state\") and pd.api.types.is_numeric_dtype(tbl[c])]\n",
    "    cand_cols = [c for c in numeric_cols if c != ev_total_col]\n",
    "\n",
    "    # === NEW DEBUG SECTION ===\n",
    "    print(f\"\\nðŸ§­ {year} Candidate columns:\")\n",
    "    for c in cand_cols:\n",
    "        print(f\"  Raw: {repr(c)}  â†’  Normalized: {repr(normalize_header(c))}  â†’  Classified as: {classify_candidate(c, year)}\")\n",
    "    print(\"\")\n",
    "\n",
    "    # normal processing but keep printouts\n",
    "    dem_cols, rep_cols, oth_cols = [], [], []\n",
    "    for c in cand_cols:\n",
    "        party = classify_candidate(c, year)\n",
    "        if party == \"DEM\":\n",
    "            dem_cols.append(c)\n",
    "        elif party == \"REP\":\n",
    "            rep_cols.append(c)\n",
    "        else:\n",
    "            oth_cols.append(c)\n",
    "\n",
    "    print(f\"  DEM cols: {dem_cols}\")\n",
    "    print(f\"  REP cols: {rep_cols}\")\n",
    "    print(f\"  OTHER cols: {oth_cols}\")\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"year\": year,\n",
    "        \"state\": tbl[\"state\"],\n",
    "        \"ev_total\": tbl[ev_total_col]\n",
    "    })\n",
    "\n",
    "    out[\"ev_dem\"]   = tbl[dem_cols].sum(axis=1, numeric_only=True) if dem_cols else 0\n",
    "    out[\"ev_rep\"]   = tbl[rep_cols].sum(axis=1, numeric_only=True) if rep_cols else 0\n",
    "    out[\"ev_other\"] = tbl[oth_cols].sum(axis=1, numeric_only=True) if oth_cols else 0\n",
    "\n",
    "    out = out.dropna(subset=[\"ev_total\"])\n",
    "    out = out[out[\"ev_total\"] > 0]\n",
    "    out[[\"ev_total\",\"ev_dem\",\"ev_rep\",\"ev_other\"]] = out[[\"ev_total\",\"ev_dem\",\"ev_rep\",\"ev_other\"]].round(0).astype(\"Int64\")\n",
    "    return out\n",
    "scrape_year(2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa4265e-b9a2-47c8-8127-a2c8405cf637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13 (StatePoliticalLeaning)",
   "language": "python",
   "name": "statepoliticalleaning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
