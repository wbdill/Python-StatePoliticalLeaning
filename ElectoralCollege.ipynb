{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4702c6e6-27da-4cba-978e-326aa426939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012a66de-48b5-47cb-ab7b-342df6982adf",
   "metadata": {},
   "source": [
    "# Electoral College\n",
    "\n",
    "After numerous failed attempts to parse the official archives.gov website there were numerous issues causing road blocks.  The main issue was the rowspan / colspan in the html table.\n",
    "\n",
    "So I manually copied/pasted the data from archives.gov into a publicly available [Google Sheet](https://docs.google.com/spreadsheets/d/1RPrW58dFiQprCtTSYP76wjHGlq0p_az3uJypPI0-PoY/edit?usp=sharing) with the 3rd row as a machine-friendly header row mapping the appropriate candidate column to `ev_dem` and `ev_rep` column header.\n",
    "\n",
    "The code below iterates over each \"year\" worksheet and combines into a single CSV.  It also fleshes out `state_po` (2 letter abbreviation) and `state_fips` (2 digit zero paded federal identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d332cdd7-77ac-4552-b125-d40374480e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting... This can take 5 to 15 seconds or more\n",
      "\n",
      "=== Header Consistency Check (first 4 cols) ===\n",
      "['state', 'state_ev_total', 'ev_dem', 'ev_rep']  → 15 sheet(s)\n",
      "\n",
      "✅ Combined 15 sheets → 780 total rows\n",
      "✅ Saved to data/electoral_college_votes_by_state_year.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# CONFIG\n",
    "# ---------------------------------------------------------------------\n",
    "SPREADSHEET_ID = \"1RPrW58dFiQprCtTSYP76wjHGlq0p_az3uJypPI0-PoY\"\n",
    "xlsx_url = f\"https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/export?format=xlsx\"\n",
    "\n",
    "expected_header = [\"state\", \"state_ev_total\", \"ev_dem\", \"ev_rep\"]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# OFFICIAL STATE → POSTAL + FIPS MAPPING (includes DC)\n",
    "# ---------------------------------------------------------------------\n",
    "state_lookup = pd.DataFrame({\n",
    "    \"state\": [\n",
    "        \"Alabama\",\"Alaska\",\"Arizona\",\"Arkansas\",\"California\",\"Colorado\",\"Connecticut\",\n",
    "        \"Delaware\",\"District of Columbia\",\"Florida\",\"Georgia\",\"Hawaii\",\"Idaho\",\"Illinois\",\n",
    "        \"Indiana\",\"Iowa\",\"Kansas\",\"Kentucky\",\"Louisiana\",\"Maine\",\"Maryland\",\"Massachusetts\",\n",
    "        \"Michigan\",\"Minnesota\",\"Mississippi\",\"Missouri\",\"Montana\",\"Nebraska\",\"Nevada\",\n",
    "        \"New Hampshire\",\"New Jersey\",\"New Mexico\",\"New York\",\"North Carolina\",\"North Dakota\",\n",
    "        \"Ohio\",\"Oklahoma\",\"Oregon\",\"Pennsylvania\",\"Rhode Island\",\"South Carolina\",\n",
    "        \"South Dakota\",\"Tennessee\",\"Texas\",\"Utah\",\"Vermont\",\"Virginia\",\"Washington\",\n",
    "        \"West Virginia\",\"Wisconsin\",\"Wyoming\"\n",
    "    ],\n",
    "    \"state_po\": [\n",
    "        \"AL\",\"AK\",\"AZ\",\"AR\",\"CA\",\"CO\",\"CT\",\"DE\",\"DC\",\"FL\",\"GA\",\"HI\",\"ID\",\"IL\",\"IN\",\"IA\",\n",
    "        \"KS\",\"KY\",\"LA\",\"ME\",\"MD\",\"MA\",\"MI\",\"MN\",\"MS\",\"MO\",\"MT\",\"NE\",\"NV\",\"NH\",\"NJ\",\"NM\",\n",
    "        \"NY\",\"NC\",\"ND\",\"OH\",\"OK\",\"OR\",\"PA\",\"RI\",\"SC\",\"SD\",\"TN\",\"TX\",\"UT\",\"VT\",\"VA\",\"WA\",\n",
    "        \"WV\",\"WI\",\"WY\"\n",
    "    ],\n",
    "    \"state_fips\": [\n",
    "        \"01\",\"02\",\"04\",\"05\",\"06\",\"08\",\"09\",\"10\",\"11\",\"12\",\"13\",\"15\",\"16\",\"17\",\"18\",\"19\",\n",
    "        \"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\n",
    "        \"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"53\",\n",
    "        \"54\",\"55\",\"56\"\n",
    "    ]\n",
    "})\n",
    "print(\"Starting... This can take 5 to 15 seconds or more\")\n",
    "# ---------------------------------------------------------------------\n",
    "# READ + PARSE GOOGLE SHEET\n",
    "# ---------------------------------------------------------------------\n",
    "sheets = pd.read_excel(xlsx_url, sheet_name=None, header=None, dtype=object)\n",
    "\n",
    "dfs = []\n",
    "headers_seen = []\n",
    "\n",
    "for sheet_name, raw in sheets.items():\n",
    "    # Skip non-year or \"info\"\n",
    "    if sheet_name.lower() == \"info\" or not re.fullmatch(r\"\\d{4}\", sheet_name):\n",
    "        continue\n",
    "\n",
    "    raw = raw.iloc[:, :4]\n",
    "    if raw.shape[0] < 3:\n",
    "        print(f\"⚠️  Skipping {sheet_name}: fewer than 3 rows\")\n",
    "        continue\n",
    "\n",
    "    # Use 3rd row (index 2) as header\n",
    "    header = (\n",
    "        raw.iloc[2, :4]\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "        .str.lower()\n",
    "        .tolist()\n",
    "    )\n",
    "    headers_seen.append(tuple(header))\n",
    "\n",
    "    if header != expected_header:\n",
    "        print(f\"⚠️  {sheet_name} header differs.\\n\"\n",
    "              f\"    Found:  {header}\\n\"\n",
    "              f\"    Expect: {expected_header}\")\n",
    "\n",
    "    # Skip top 3 rows\n",
    "    df = raw.iloc[3:, :4].copy()\n",
    "    df.columns = header\n",
    "    df = df.dropna(how=\"all\")\n",
    "\n",
    "    # Trim whitespace\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype == \"object\":\n",
    "            df[c] = df[c].astype(str).str.strip()\n",
    "\n",
    "    # Merge state_po + fips\n",
    "    df = df.merge(state_lookup, how=\"left\", on=\"state\")\n",
    "\n",
    "    # Reorder columns: year first\n",
    "    df.insert(0, \"year\", sheet_name)\n",
    "    df = df[[\"year\", \"state\", \"state_po\", \"state_fips\", \"state_ev_total\", \"ev_dem\", \"ev_rep\"]]\n",
    "\n",
    "    dfs.append(df)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# CONSISTENCY + SAVE\n",
    "# ---------------------------------------------------------------------\n",
    "if headers_seen:\n",
    "    counts = pd.Series(headers_seen).value_counts()\n",
    "    print(\"\\n=== Header Consistency Check (first 4 cols) ===\")\n",
    "    for hdr, n in counts.items():\n",
    "        print(f\"{list(hdr)}  → {n} sheet(s)\")\n",
    "\n",
    "df_ev = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Optional: coerce numeric columns\n",
    "num_cols = [\"state_ev_total\", \"ev_dem\", \"ev_rep\"]\n",
    "for c in num_cols:\n",
    "    df_ev[c] = pd.to_numeric(df_ev[c], errors=\"coerce\").astype(\"Int64\")\n",
    "    #df_ev[c] = pd.to_integer(df_ev[c], errors=\"coerce\")\n",
    "\n",
    "df_ev.to_csv(\"data/electoral_college_votes_by_state_year.csv\", index=False)\n",
    "\n",
    "print(f\"\\n✅ Combined {len(dfs)} sheets → {len(df_ev)} total rows\")\n",
    "print(\"✅ Saved to data/electoral_college_votes_by_state_year.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff900c0-7a16-42d2-9608-4fe198d2a6b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13 (StatePoliticalLeaning)",
   "language": "python",
   "name": "statepoliticalleaning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
